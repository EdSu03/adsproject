{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-15T16:33:50.618256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import re\n",
    "\n",
    "def clean_parquet_files_yellow_taxi(input_dir=\"data\", output_dir=\"cleaned_data\"):\n",
    "    \"\"\"\n",
    "    This function processes multiple Parquet files from the 'data' folder by applying data cleaning steps.\n",
    "    Cleaned files are saved to the 'cleaned_data' directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. Ensure output directory exists\n",
    "    # -------------------------\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2. Find all Parquet files in the input directory\n",
    "    # -------------------------\n",
    "    file_list = glob.glob(os.path.join(input_dir, \"yellow_tripdata_2024-*.parquet\"))\n",
    "\n",
    "    if not file_list:\n",
    "        print(\"‚ùå No files found in './data'. Please check the folder and file names!\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Found {len(file_list)} files in '{input_dir}/'. Starting data cleaning...\\n\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 3. Process all files with a single progress bar\n",
    "    # -------------------------\n",
    "    with tqdm(total=len(file_list), desc=\"Cleaning Progress\", unit=\"file\") as pbar:\n",
    "\n",
    "        for file_path in file_list:\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.1 Read Parquet file and convert all column names to lowercase\n",
    "            # -------------------------\n",
    "            df = pd.read_parquet(file_path, engine=\"pyarrow\")  # Use \"fastparquet\" if needed\n",
    "            df.columns = df.columns.str.lower()\n",
    "                        \n",
    "            # -------------------------\n",
    "            # 3.2 Handle missing values\n",
    "            # -------------------------\n",
    "            df[\"passenger_count\"] = df[\"passenger_count\"].fillna(1) # Set NaN to default 1\n",
    "            df[\"trip_distance\"] = df[\"trip_distance\"].fillna(0)\n",
    "            df.fillna(0, inplace=True)\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.3 Remove unnecessary columns\n",
    "            # -------------------------\n",
    "            if \"store_and_fwd_flag\" in df.columns:\n",
    "                df.drop(columns=[\"store_and_fwd_flag\"], inplace=True)\n",
    "            if \"ratecodeid\" in df.columns:\n",
    "                df.drop(columns=[\"ratecodeid\"], inplace=True)\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.4 Convert datetime columns\n",
    "            # -------------------------\n",
    "            df[\"pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "            df[\"dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "            df.drop(columns=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"], inplace=True)\n",
    "            \n",
    "            # -------------------------\n",
    "            # 3.4.5 Filter rows with incorrect year or month based on file name\n",
    "            # -------------------------\n",
    "            filename = os.path.basename(file_path)\n",
    "            match = re.search(r\"yellow_tripdata_(\\d{4})-(\\d{2})\\.parquet\", filename)\n",
    "            if match:\n",
    "                expected_year = int(match.group(1))\n",
    "                expected_month = int(match.group(2))\n",
    "                df = df[\n",
    "                    (df[\"pickup_datetime\"].dt.year == expected_year) &\n",
    "                    (df[\"pickup_datetime\"].dt.month == expected_month)\n",
    "                ]\n",
    "            else:\n",
    "                print(f\"Warning: Filename {filename} doesn't match expected format. Date filtering skipped.\")\n",
    "                \n",
    "            # -------------------------\n",
    "            # 3.5 Calculate trip duration in minutes\n",
    "            # -------------------------\n",
    "            df[\"trip_duration\"] = (df[\"dropoff_datetime\"] - df[\"pickup_datetime\"]).dt.total_seconds() / 60\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.6 Remove extreme values\n",
    "            # -------------------------\n",
    "            df = df[df[\"trip_distance\"] >= 0.05] # Remove trips with distance < 0.05 miles\n",
    "            df = df[df[\"fare_amount\"] > 0]  # Remove negative fare amounts\n",
    "            df = df[(df[\"passenger_count\"] > 0)]  # Keep passenger count bigger than 0\n",
    "            df = df[(df[\"trip_duration\"] >= 1) & (df[\"trip_duration\"] <= 180)]  # Keep trip duration (1-180 mins)\n",
    "            df = df[df['payment_type'].isin([1, 2, 3, 4, 5, 6])] #The possible payment types\n",
    "            \n",
    "            # Remove extremely high trip distances\n",
    "            df = df[df[\"trip_distance\"] <= 50]  # Only keep trips ‚â§ 50 miles\n",
    "            \n",
    "            # Define reasonable upper limits for monetary values\n",
    "            fare_limit = df[\"fare_amount\"].quantile(0.99)  # 99% quantile\n",
    "            tip_limit = df[\"tip_amount\"].quantile(0.99)\n",
    "            total_limit = df[\"total_amount\"].quantile(0.99)\n",
    "\n",
    "            # Apply filtering\n",
    "            df = df[\n",
    "                (df[\"fare_amount\"] <= fare_limit) &\n",
    "                (df[\"tip_amount\"] <= tip_limit) &\n",
    "                (df[\"total_amount\"] <= total_limit)\n",
    "            ]\n",
    "            \n",
    "            # -------------------------\n",
    "            # 3.6.5 Ensure monetary values appart from fare_amountare non-negative \n",
    "            # -------------------------\n",
    "            monetary_columns = [\n",
    "                'extra', 'mta_tax', 'improvement_surcharge', 'tip_amount',\n",
    "                'tolls_amount', 'total_amount', 'congestion_surcharge', 'airport_fee'\n",
    "             ]\n",
    "            df = df[(df[monetary_columns] >= 0).all(axis=1)]\n",
    "            # -------------------------\n",
    "            # 3.7 Drop duplicate rows\n",
    "            # -------------------------\n",
    "            df.drop_duplicates(inplace=True)\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.8 Rename columns for better readability (CamelCase) and rearrange columns\n",
    "            # -------------------------\n",
    "            df.rename(columns={\n",
    "                \"pickup_datetime\": \"PickupDatetime\",\n",
    "                \"dropoff_datetime\": \"DropoffDatetime\",\n",
    "                \"vendorid\": \"VendorID\",\n",
    "                \"trip_duration\": \"TripDuration\",\n",
    "                \"passenger_count\": \"PassengerCount\",\n",
    "                \"trip_distance\": \"TripDistance\",\n",
    "                \"pulocationid\": \"PULocationID\",\n",
    "                \"dolocationid\": \"DOLocationID\",\n",
    "                \"payment_type\": \"PaymentType\",\n",
    "                \"fare_amount\": \"FareAmount\",\n",
    "                \"extra\": \"ExtraCharges\",\n",
    "                \"mta_tax\": \"MTATax\",\n",
    "                \"tip_amount\": \"TipAmount\",\n",
    "                \"tolls_amount\": \"TollsAmount\",\n",
    "                \"improvement_surcharge\": \"ImprovementSurcharge\",\n",
    "                \"total_amount\": \"TotalAmount\",\n",
    "                \"congestion_surcharge\": \"CongestionSurcharge\",\n",
    "                \"airport_fee\": \"AirportFee\"\n",
    "            }, inplace=True)\n",
    "            \n",
    "            df = df[[\n",
    "                \"VendorID\", \"PickupDatetime\", \"DropoffDatetime\", \"TripDuration\",\n",
    "                \"PassengerCount\", \"TripDistance\", \"PULocationID\", \"DOLocationID\",\n",
    "                \"PaymentType\", \"FareAmount\", \"ExtraCharges\", \"MTATax\", \"TipAmount\",\n",
    "                \"TollsAmount\", \"ImprovementSurcharge\", \"TotalAmount\",\n",
    "                \"CongestionSurcharge\", \"AirportFee\"\n",
    "            ]]\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.9 Save cleaned file in the output directory\n",
    "            # -------------------------\n",
    "            output_filename = \"cleaned_\" + os.path.basename(file_path)\n",
    "            output_path = os.path.join(output_dir, os.path.basename(output_filename))\n",
    "            df.to_parquet(output_path, index=False)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"\\nüéâ Yellow Taxi data successfully cleaned and saved in 'cleaned_data/'!\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. Run the function\n",
    "# -------------------------\n",
    "clean_parquet_files_yellow_taxi()"
   ],
   "id": "ae8be2ed35059f48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 12 files in 'data/'. Starting data cleaning...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Progress:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [00:34<00:48,  6.96s/file]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T16:30:47.121967Z",
     "start_time": "2025-03-15T16:30:45.555325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import re\n",
    "\n",
    "def clean_parquet_files_green_taxi(input_dir=\"data\", output_dir=\"cleaned_data\"):\n",
    "    \"\"\"\n",
    "    This function processes multiple Green Taxi Parquet files from the 'data' folder by applying data cleaning steps.\n",
    "    Cleaned files are saved to the 'cleaned_data' directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. Ensure output directory exists\n",
    "    # -------------------------\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2. Find all Green Taxi Parquet files in the input directory\n",
    "    # -------------------------\n",
    "    file_list = glob.glob(os.path.join(input_dir, \"green_tripdata_2024-*.parquet\"))\n",
    "\n",
    "    if not file_list:\n",
    "        print(\"‚ùå No Green Taxi files found in './data'. Please check the folder and file names!\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Found {len(file_list)} Green Taxi files in '{input_dir}/'. Starting data cleaning...\\n\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 3. Process all files with a single progress bar\n",
    "    # -------------------------\n",
    "    with tqdm(total=len(file_list), desc=\"Cleaning Green Taxi Data\", unit=\"file\") as pbar:\n",
    "\n",
    "        for file_path in file_list:\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.1 Read Parquet file and convert all column names to lowercase\n",
    "            # -------------------------\n",
    "            df = pd.read_parquet(file_path, engine=\"pyarrow\")  \n",
    "            df.columns = df.columns.str.lower()\n",
    "                        \n",
    "            # -------------------------\n",
    "            # 3.2 Handle missing values\n",
    "            # -------------------------\n",
    "            df[\"passenger_count\"] = df[\"passenger_count\"].fillna(1)  # Default to 1\n",
    "            df[\"trip_distance\"] = df[\"trip_distance\"].fillna(0)\n",
    "            df.fillna(0, inplace=True)\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.3 Remove unnecessary columns and add df[\"airport_fee\"] = 0 to be consistent with yellow taxi\n",
    "            # -------------------------\n",
    "            drop_columns = [\"store_and_fwd_flag\", \"ehail_fee\", \"trip_type\"]\n",
    "            df.drop(columns=[col for col in drop_columns if col in df.columns], inplace=True)\n",
    "            \n",
    "            df[\"airport_fee\"] = 0\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.4 Convert datetime columns\n",
    "            # -------------------------\n",
    "            df[\"pickup_datetime\"] = pd.to_datetime(df[\"lpep_pickup_datetime\"])\n",
    "            df[\"dropoff_datetime\"] = pd.to_datetime(df[\"lpep_dropoff_datetime\"])\n",
    "            df.drop(columns=[\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\"], inplace=True)\n",
    "            \n",
    "            # -------------------------\n",
    "            # 3.4.5 Filter rows with incorrect year or month based on file name\n",
    "            # -------------------------\n",
    "            filename = os.path.basename(file_path)\n",
    "            match = re.search(r\"green_tripdata_(\\d{4})-(\\d{2})\\.parquet\", filename)\n",
    "            if match:\n",
    "                expected_year = int(match.group(1))\n",
    "                expected_month = int(match.group(2))\n",
    "                df = df[\n",
    "                    (df[\"pickup_datetime\"].dt.year == expected_year) &\n",
    "                    (df[\"pickup_datetime\"].dt.month == expected_month)\n",
    "                ]\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Warning: Filename {filename} doesn't match expected format. Date filtering skipped.\")\n",
    "                \n",
    "            # -------------------------\n",
    "            # 3.5 Calculate trip duration in minutes\n",
    "            # -------------------------\n",
    "            df[\"trip_duration\"] = (df[\"dropoff_datetime\"] - df[\"pickup_datetime\"]).dt.total_seconds() / 60\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.6 Remove extreme values\n",
    "            # -------------------------\n",
    "            df = df[(df[\"trip_distance\"] >= 0.05) & (df[\"trip_distance\"] <= 50)]  # Keep trips within 0.05 - 50 miles\n",
    "            df = df[df[\"fare_amount\"] > 0]  # Remove negative fares\n",
    "            df = df[(df[\"passenger_count\"] > 0)]  # Remove invalid passenger counts\n",
    "            df = df[(df[\"trip_duration\"] >= 1) & (df[\"trip_duration\"] <= 180)]  # Keep trip duration (1-180 mins)\n",
    "            df = df[df['payment_type'].isin([1, 2, 3, 4, 5, 6])]  # Valid payment types\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.6.5 Handle monetary value outliers\n",
    "            # -------------------------\n",
    "            fare_limit = df[\"fare_amount\"].quantile(0.99)  \n",
    "            tip_limit = df[\"tip_amount\"].quantile(0.99)\n",
    "            total_limit = df[\"total_amount\"].quantile(0.99)\n",
    "\n",
    "            df = df[\n",
    "                (df[\"fare_amount\"] <= fare_limit) &\n",
    "                (df[\"tip_amount\"] <= tip_limit) &\n",
    "                (df[\"total_amount\"] <= total_limit)\n",
    "            ]\n",
    "\n",
    "            monetary_columns = [\n",
    "                'extra', 'mta_tax', 'improvement_surcharge', 'tip_amount',\n",
    "                'tolls_amount', 'total_amount', 'congestion_surcharge'\n",
    "            ]\n",
    "            df = df[(df[monetary_columns] >= 0).all(axis=1)]\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.7 Drop duplicate rows\n",
    "            # -------------------------\n",
    "            df.drop_duplicates(inplace=True)\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.8 Rename and reorder columns\n",
    "            # -------------------------\n",
    "            df.rename(columns={\n",
    "                \"pickup_datetime\": \"PickupDatetime\",\n",
    "                \"dropoff_datetime\": \"DropoffDatetime\",\n",
    "                \"vendorid\": \"VendorID\",\n",
    "                \"trip_duration\": \"TripDuration\",\n",
    "                \"passenger_count\": \"PassengerCount\",\n",
    "                \"trip_distance\": \"TripDistance\",\n",
    "                \"pulocationid\": \"PULocationID\",\n",
    "                \"dolocationid\": \"DOLocationID\",\n",
    "                \"payment_type\": \"PaymentType\",\n",
    "                \"fare_amount\": \"FareAmount\",\n",
    "                \"extra\": \"ExtraCharges\",\n",
    "                \"mta_tax\": \"MTATax\",\n",
    "                \"tip_amount\": \"TipAmount\",\n",
    "                \"tolls_amount\": \"TollsAmount\",\n",
    "                \"improvement_surcharge\": \"ImprovementSurcharge\",\n",
    "                \"total_amount\": \"TotalAmount\",\n",
    "                \"congestion_surcharge\": \"CongestionSurcharge\",\n",
    "                \"airport_fee\": \"AirportFee\"\n",
    "            }, inplace=True)\n",
    "            \n",
    "            df = df[[\n",
    "                \"VendorID\", \"PickupDatetime\", \"DropoffDatetime\", \"TripDuration\",\n",
    "                \"PassengerCount\", \"TripDistance\", \"PULocationID\", \"DOLocationID\",\n",
    "                \"PaymentType\", \"FareAmount\", \"ExtraCharges\", \"MTATax\", \"TipAmount\",\n",
    "                \"TollsAmount\", \"ImprovementSurcharge\", \"TotalAmount\",\n",
    "                \"CongestionSurcharge\", \"AirportFee\"\n",
    "            ]]\n",
    "\n",
    "            # -------------------------\n",
    "            # 3.9 Save cleaned file in the output directory\n",
    "            # -------------------------\n",
    "            output_filename = \"cleaned_\" + os.path.basename(file_path)\n",
    "            output_path = os.path.join(output_dir, os.path.basename(output_filename))\n",
    "            df.to_parquet(output_path, index=False)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"\\nüéâ Green Taxi data successfully cleaned and saved in 'cleaned_data/'!\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. Run the function\n",
    "# -------------------------\n",
    "clean_parquet_files_green_taxi()\n"
   ],
   "id": "db226f16cd3c181d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 12 Green Taxi files in 'data/'. Starting data cleaning...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Green Taxi Data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  7.78file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéâ Green Taxi data successfully cleaned and saved in 'cleaned_data/'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "caa1240c056cf13e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
