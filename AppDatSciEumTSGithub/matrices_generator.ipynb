{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18845b31",
   "metadata": {},
   "source": [
    "Generate a probability matrix for trip dropoff zone, given the pickup zone, at one hour intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_transition_zoneMat(parquet_path: str,\n",
    "                            num_zones: int = 266,\n",
    "                            datetime_col: str = 'tpep_pickup_datetime',\n",
    "                            pu_col: str = 'PULocationID',\n",
    "                            do_col: str = 'DOLocationID',\n",
    "                            output_path: str = 'zone_transition_probabilities_2024.npy'):\n",
    "    \"\"\"\n",
    "    Reads trip data from Parquet, computes a (num_zones x num_zones x 24) tensor\n",
    "    of transition probabilities P(dropoff=j | pickup=i, hour=h), and saves it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parquet_path : str\n",
    "        Path to yellow_taxi_tripdata_2024_clean.parquet.\n",
    "    num_zones : int\n",
    "        Number of taxi zones (default: 266).\n",
    "    datetime_col : str\n",
    "        Name of the column with pickup timestamps.\n",
    "    pu_col : str\n",
    "        Name of the column with pickup zone IDs (1..num_zones).\n",
    "    do_col : str\n",
    "        Name of the column with dropoff zone IDs (1..num_zones).\n",
    "    output_path : str\n",
    "        Where to write the resulting .npy file.\n",
    "    \"\"\"\n",
    "    #Load parquet\n",
    "    df = pd.read_parquet(parquet_path, engine='pyarrow')\n",
    "    \n",
    "    #Extract hour-of-day [0–23]\n",
    "    df['hour'] = pd.to_datetime(df[datetime_col]).dt.hour\n",
    "    \n",
    "    #Count trips by (hour, pickup_zone, dropoff_zone)\n",
    "    grouped = (\n",
    "        df\n",
    "        .groupby(['hour', pu_col, do_col])\n",
    "        .size()\n",
    "        .reset_index(name='count')\n",
    "    )\n",
    "    \n",
    "    \n",
    "    tensor = np.zeros((num_zones, num_zones, 24), dtype=np.float64)\n",
    "    \n",
    "    #For each hour, build and normalize the (266×266) matrix\n",
    "    zones = np.arange(1, num_zones+1)\n",
    "    for h in range(24):\n",
    "        sub = grouped[grouped['hour'] == h]\n",
    "        #pivot to matrix form, missing entries → 0\n",
    "        mat = (\n",
    "            sub\n",
    "            .pivot_table(index=pu_col,\n",
    "                         columns=do_col,\n",
    "                         values='count',\n",
    "                         fill_value=0)\n",
    "            .reindex(index=zones, columns=zones, fill_value=0)\n",
    "            .to_numpy()\n",
    "        )\n",
    "        #normalize each row to sum to 1 (where row sum > 0)\n",
    "        row_sums = mat.sum(axis=1, keepdims=True)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            mat = np.divide(mat, row_sums, where=(row_sums != 0))\n",
    "        tensor[:, :, h] = mat\n",
    "    \n",
    "    #Save as .npy for fast loading\n",
    "    np.save(output_path, tensor)\n",
    "    print(f\"Saved transition tensor to {output_path} \"\n",
    "          f\"(shape = {tensor.shape}, dtype = {tensor.dtype})\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5376393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved transition tensor to zone_transition_probabilities_2024.npy (shape = (266, 266, 24), dtype = float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "build_transition_zoneMat(\n",
    "        parquet_path='yellow_taxi_tripdata_2024_clean.parquet',\n",
    "        output_path='zone_transition_probabilities_2024.npy'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244f957",
   "metadata": {},
   "source": [
    "Now the same type of matrix but for average fare amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce912ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_avg_earnings_matrix(\n",
    "    parquet_path: str,\n",
    "    num_zones: int = 266,\n",
    "    datetime_col: str = 'tpep_pickup_datetime',\n",
    "    pu_col: str = 'PULocationID',\n",
    "    do_col: str = 'DOLocationID',\n",
    "    amount_col: str = 'total_amount',\n",
    "    output_path: str = 'zone_avg_earnings_2024.npy'\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads trip data from Parquet, computes a (num_zones x num_zones x 24) tensor\n",
    "    of average earnings per trip: E[amount_col | pickup=i, dropoff=j, hour=h],\n",
    "    and saves it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parquet_path : str\n",
    "        Path to your cleaned 2024 trips Parquet file.\n",
    "    num_zones : int\n",
    "        Number of taxi zones (default: 266).\n",
    "    datetime_col : str\n",
    "        Column name for pickup timestamps.\n",
    "    pu_col : str\n",
    "        Column name for pickup zone IDs (1..num_zones).\n",
    "    do_col : str\n",
    "        Column name for drop‑off zone IDs (1..num_zones).\n",
    "    amount_col : str\n",
    "        Column name for the money earned on each trip (e.g. 'total_amount').\n",
    "    output_path : str\n",
    "        Filename for saving the resulting .npy tensor.\n",
    "    \"\"\"\n",
    "    #Load data\n",
    "    df = pd.read_parquet(parquet_path, engine='pyarrow')\n",
    "\n",
    "    #Extract hour of day 0–23\n",
    "    df['hour'] = pd.to_datetime(df[datetime_col]).dt.hour\n",
    "\n",
    "    #Compute mean earnings per (hour, pickup, dropoff)\n",
    "    grouped = (\n",
    "        df\n",
    "        .groupby(['hour', pu_col, do_col])[amount_col]\n",
    "        .mean()\n",
    "        .reset_index(name='avg_amount')\n",
    "    )\n",
    "\n",
    "    \n",
    "    tensor = np.full((num_zones, num_zones, 24), np.nan, dtype=np.float64)\n",
    "\n",
    "    #For each hour, pivot into a 266×266 matrix\n",
    "    zones = np.arange(1, num_zones + 1)\n",
    "    for h in range(24):\n",
    "        sub = grouped[grouped['hour'] == h]\n",
    "        mat = (\n",
    "            sub\n",
    "            .pivot_table(\n",
    "                index=pu_col,\n",
    "                columns=do_col,\n",
    "                values='avg_amount',\n",
    "                fill_value=np.nan\n",
    "            )\n",
    "            .reindex(index=zones, columns=zones)\n",
    "            .to_numpy()\n",
    "        )\n",
    "        tensor[:, :, h] = mat\n",
    "\n",
    "    \n",
    "    np.save(output_path, tensor)\n",
    "    print(f\"Saved average‐earnings tensor to {output_path} \"\n",
    "          f\"(shape={tensor.shape}, dtype={tensor.dtype})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7efcc7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved average‐earnings tensor to zone_avg_earnings_2024.npy (shape=(266, 266, 24), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "build_avg_earnings_matrix(\n",
    "    parquet_path='yellow_taxi_tripdata_2024_clean.parquet',\n",
    "    output_path='zone_avg_earnings_2024.npy'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
