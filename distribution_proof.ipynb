{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57deaa9e-0a62-4034-b3af-c1350f89ec36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_helper_functions as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3782d74f-2f70-4200-98f0-a471f268b176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>NextPU</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>129</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>263</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>236</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID  DOLocationID  NextPU  Hour\n",
       "0           166            74      74     1\n",
       "1            74            42      82     1\n",
       "2            83           129     116     1\n",
       "3            74           263       7     0\n",
       "4            74           236      80     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_parquet(\"all_cleaned_data_augmented.parquet\")\n",
    "df = mod.necessary_fields(df)\n",
    "df['Hour'] = df['DropoffDatetime'].apply(mod.round_time_to_int)\n",
    "df = df.drop(columns = ['DropoffDatetime', 'PickupDatetime','TripDuration', 'TripDistance', 'FareAmount', 'TipAmount'])\n",
    "df['PULocationID'] = df['PULocationID'].astype(int)\n",
    "df['DOLocationID'] = df['DOLocationID'].astype(int)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8959cd2-aa7f-43c2-9d81-97d9f38c8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chi_squared(group):\n",
    "    counts_pu = group['PULocationID'].value_counts().sort_index()\n",
    "    counts_nextpu = group['DOLocationID'].value_counts().sort_index()\n",
    "    \n",
    "    all_ids = sorted(set(counts_pu.index).union(set(counts_nextpu.index)))\n",
    "\n",
    "    f_obs = counts_nextpu.reindex(all_ids, fill_value=0).values\n",
    "    f_exp = counts_pu.reindex(all_ids, fill_value=0).values\n",
    "\n",
    "    # Filter out zero-expected entries\n",
    "    mask = f_exp > 0\n",
    "    f_obs = f_obs[mask]\n",
    "    f_exp = f_exp[mask]\n",
    "\n",
    "    # Normalize expected to match total observed\n",
    "    f_exp = f_exp * (f_obs.sum() / f_exp.sum())\n",
    "\n",
    "    # Only run test if valid\n",
    "    if len(f_obs) > 0 and np.all(f_exp > 0):\n",
    "        stat, p = chisquare(f_obs=f_obs, f_exp=f_exp)\n",
    "    else:\n",
    "        stat, p = np.nan, np.nan\n",
    "    return stat, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4725c982-b2b3-41e7-bea8-0f1b3abd98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chi_squared_by_singular(df):\n",
    "    \n",
    "\n",
    "    results = []\n",
    "\n",
    "    for hour, group in df.groupby('Hour'):\n",
    "        counts_pu = group['PULocationID'].value_counts().sort_index()\n",
    "        counts_nextpu = group['DOLocationID'].value_counts().sort_index()\n",
    "\n",
    "        all_ids = sorted(set(counts_pu.index).union(set(counts_nextpu.index)))\n",
    "\n",
    "        f_obs = counts_nextpu.reindex(all_ids, fill_value=0).values\n",
    "        f_exp = counts_pu.reindex(all_ids, fill_value=0).values\n",
    "\n",
    "        # Filter out zero expected frequencies to avoid divide-by-zero\n",
    "        mask = f_exp > 0\n",
    "        f_obs = f_obs[mask]\n",
    "        f_exp = f_exp[mask]\n",
    "\n",
    "        # Normalize expected counts to match total observed\n",
    "        if f_exp.sum() == 0:\n",
    "            stat, p = np.nan, np.nan\n",
    "        else:\n",
    "            f_exp = f_exp * (f_obs.sum() / f_exp.sum())\n",
    "            stat, p = chisquare(f_obs=f_obs, f_exp=f_exp)\n",
    "\n",
    "        results.append({\n",
    "            'Hour': hour,\n",
    "            'Chi2_Stat': stat,\n",
    "            'p_value': p,\n",
    "            'N': len(group)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19bbb082-055a-4ef0-a031-2644b1e01796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chi2_Stat': 724168083.1631432, 'p_value': 0.0, 'N': 24145198}\n"
     ]
    }
   ],
   "source": [
    "def run_chi_squared_unified(df):\n",
    "    # Get counts for PULocationID and NextPU\n",
    "    counts_pu = df['PULocationID'].value_counts().sort_index()\n",
    "    counts_nextpu = df['NextPU'].value_counts().sort_index()\n",
    "\n",
    "    # Combine the counts into a single list of all possible values (PULocationID + NextPU)\n",
    "    all_ids = sorted(set(counts_pu.index).union(set(counts_nextpu.index)))\n",
    "\n",
    "    # Reindex the counts to make sure both distributions align\n",
    "    f_obs = counts_nextpu.reindex(all_ids, fill_value=0).values\n",
    "    f_exp = counts_pu.reindex(all_ids, fill_value=0).values\n",
    "\n",
    "    # Perform Chi-squared test\n",
    "    stat, p_value = chisquare(f_obs=f_obs, f_exp=f_exp)\n",
    "\n",
    "    return {\n",
    "        'Chi2_Stat': stat,\n",
    "        'p_value': p_value,\n",
    "        'N': len(df)\n",
    "    }\n",
    "\n",
    "result = run_chi_squared_unified(df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ed772a0-6612-4ea5-bdf3-a9afba3facce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (dropoff_id, hour), group \u001b[38;5;129;01min\u001b[39;00m grouped:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(group) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m:  \u001b[38;5;66;03m# Filter small groups\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m         stat, p \u001b[38;5;241m=\u001b[39m run_chi_squared_unified(group)\n\u001b[1;32m      6\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOLocationID\u001b[39m\u001b[38;5;124m'\u001b[39m: dropoff_id,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m: hour,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(group)\n\u001b[1;32m     12\u001b[0m         })\n\u001b[1;32m     14\u001b[0m result \u001b[38;5;241m=\u001b[39m run_chi_squared_unified(df)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby(['NextPU', 'Hour'])\n",
    "results = []\n",
    "for (dropoff_id, hour), group in grouped:\n",
    "    if len(group) >= 30:  # Filter small groups\n",
    "        stat, p = run_chi_squared_unified(group)\n",
    "        results.append({\n",
    "            'DOLocationID': dropoff_id,\n",
    "            'Hour': hour,\n",
    "            'Chi2_Stat': stat,\n",
    "            'p_value': p,\n",
    "            'N': len(group)\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9872f8e-f4f8-4282-b596-db53d9f22b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant differences in 310 groups out of 310 total.\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optional: filter to groups where distributions are significantly different\n",
    "significant = results_df[results_df['p_value'] < 0.05]\n",
    "print(f\"Significant differences in {len(significant)} groups out of {len(results_df)} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd85eddb-0d02-4b1d-a3d4-9de3c4c508a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Hour     Chi2_Stat  p_value        N\n",
      "0      0  4.754270e+06      0.0  1207203\n",
      "1      1  6.159877e+06      0.0  1763888\n",
      "2      2  3.448100e+06      0.0  1166909\n",
      "3      3  2.045648e+06      0.0   738832\n",
      "4      4  1.241154e+06      0.0   477572\n",
      "5      5  9.241075e+05      0.0   281212\n",
      "6      6  1.471172e+06      0.0   469089\n",
      "7      7  1.553347e+06      0.0  1143866\n",
      "8      8  1.163970e+06      0.0  2073441\n",
      "9      9  1.252724e+06      0.0  2735951\n",
      "10    10  1.101830e+06      0.0  3086430\n",
      "11    11  9.916578e+05      0.0  3360550\n",
      "12    12  8.953423e+05      0.0  3685443\n",
      "13    13  4.879648e+05      0.0  1954812\n"
     ]
    }
   ],
   "source": [
    "results_by_hour = run_chi_squared_by_singular(df)\n",
    "print(results_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37dda409-b9a5-4cf8-ab00-8a8f7217b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def run_jsd_by_zone_and_hour(df):\n",
    "    results = []\n",
    "\n",
    "    # Make sure Hour column exists\n",
    "    if 'Hour' not in df.columns:\n",
    "        df['Hour'] = pd.to_datetime(df['tpep_dropoff_datetime']).dt.hour\n",
    "\n",
    "    # Group by DOLocationID and Hour\n",
    "    grouped = df.groupby(['DOLocationID', 'Hour'])\n",
    "\n",
    "    for (zone, hour), group in grouped:\n",
    "        counts_pu = group['PULocationID'].value_counts().sort_index()\n",
    "        counts_nextpu = group['NextPU'].value_counts().sort_index()\n",
    "\n",
    "        all_ids = sorted(set(counts_pu.index).union(set(counts_nextpu.index)))\n",
    "\n",
    "        dist_pu = counts_pu.reindex(all_ids, fill_value=0).values.astype(float)\n",
    "        dist_nextpu = counts_nextpu.reindex(all_ids, fill_value=0).values.astype(float)\n",
    "\n",
    "        # Convert to probability distributions\n",
    "        if dist_pu.sum() == 0 or dist_nextpu.sum() == 0:\n",
    "            jsd = np.nan\n",
    "        else:\n",
    "            dist_pu /= dist_pu.sum()\n",
    "            dist_nextpu /= dist_nextpu.sum()\n",
    "            jsd = jensenshannon(dist_pu, dist_nextpu, base=2)\n",
    "\n",
    "        results.append({\n",
    "            'DOLocationID': zone,\n",
    "            'Hour': hour,\n",
    "            'JSD': jsd,\n",
    "            'N': len(group)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def run_jsd_by_zone(df):\n",
    "    results = []\n",
    "\n",
    "    for zone, group in df.groupby('DOLocationID'):\n",
    "        counts_pu = group['PULocationID'].value_counts().sort_index()\n",
    "        counts_nextpu = group['NextPU'].value_counts().sort_index()\n",
    "\n",
    "        all_ids = sorted(set(counts_pu.index).union(set(counts_nextpu.index)))\n",
    "\n",
    "        dist_pu = counts_pu.reindex(all_ids, fill_value=0).values.astype(float)\n",
    "        dist_nextpu = counts_nextpu.reindex(all_ids, fill_value=0).values.astype(float)\n",
    "\n",
    "        # Convert to probability distributions\n",
    "        if dist_pu.sum() == 0 or dist_nextpu.sum() == 0:\n",
    "            jsd = np.nan\n",
    "        else:\n",
    "            dist_pu /= dist_pu.sum()\n",
    "            dist_nextpu /= dist_nextpu.sum()\n",
    "            jsd = jensenshannon(dist_pu, dist_nextpu, base=2)  # base-2 gives range 0â€“1\n",
    "\n",
    "        results.append({\n",
    "            'DOLocationID': zone,\n",
    "            'JSD': jsd,\n",
    "            'N': len(group)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2308efee-379a-4461-9ec9-9515c78cfcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DOLocationID       JSD     N\n",
      "83             84  1.000000     8\n",
      "180           187  1.000000    33\n",
      "101           105  1.000000    13\n",
      "196           204  1.000000     3\n",
      "1               2  1.000000    43\n",
      "43             44  0.994385   123\n",
      "0               1  0.994341  3437\n",
      "150           156  0.991031    56\n",
      "237           245  0.990774    75\n",
      "243           251  0.987096   117\n",
      "     DOLocationID       JSD       N\n",
      "41             42  0.742455  100164\n",
      "40             41  0.749688  139706\n",
      "146           152  0.750927   44692\n",
      "73             74  0.763960  190686\n",
      "153           159  0.764365    9116\n",
      "68             69  0.769780   10071\n",
      "160           166  0.774174  196921\n",
      "162           168  0.776722   17236\n",
      "239           247  0.778511   11219\n",
      "161           167  0.779427    4046\n"
     ]
    }
   ],
   "source": [
    "results_jsd = run_jsd_by_zone(df)\n",
    "print(results_jsd.sort_values('JSD', ascending=False).head(10))  # Most different\n",
    "print(results_jsd.sort_values('JSD').head(10))  # Most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e67a29-6b4f-4686-a937-2864174b2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kl_divergence_unified(df):\n",
    "\n",
    "    counts_pu = df['DOLocationID'].value_counts().sort_index()\n",
    "    counts_nextpu = df['PULocationID'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "    all_ids = sorted(set(counts_pu.index).union(set(counts_nextpu.index)))\n",
    "\n",
    "    # Reindex the counts to make sure both distributions align\n",
    "    dist_pu = counts_pu.reindex(all_ids, fill_value=0).values.astype(float)\n",
    "    dist_nextpu = counts_nextpu.reindex(all_ids, fill_value=0).values.astype(float)\n",
    "\n",
    "\n",
    "    if dist_pu.sum() == 0 or dist_nextpu.sum() == 0:\n",
    "        kl_div = np.nan\n",
    "    else:\n",
    "        dist_pu /= dist_pu.sum()\n",
    "        dist_nextpu /= dist_nextpu.sum()\n",
    "\n",
    "\n",
    "        epsilon = 1e-10\n",
    "        dist_pu = np.maximum(dist_pu, epsilon)\n",
    "        dist_nextpu = np.maximum(dist_nextpu, epsilon)\n",
    "\n",
    "        # KL Divergence (P || Q)\n",
    "        kl_div = np.sum(dist_pu * np.log(dist_pu / dist_nextpu))\n",
    "\n",
    "    return {\n",
    "        'KL_Divergence': kl_div,\n",
    "        'N': len(df)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a78e2f80-8b53-45f2-bd77-57c56ab12547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KL_Divergence': 0.1213840937824795, 'N': 24145198}\n"
     ]
    }
   ],
   "source": [
    "result = run_kl_divergence_unified(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81c8ce-9542-4dea-a6e4-c699e16c0afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
